{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practise Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7RMrg62LCUWyU2wJ9YXkL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atp800/R42-AI-Course/blob/master/Practise_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4_YhDwA0fAo",
        "colab_type": "text"
      },
      "source": [
        "# **Practising using Google Colab with neural networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmej0ogz2Utj",
        "colab_type": "text"
      },
      "source": [
        "**Recreating a transformer network**\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evbxLHfR0QpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"input text\"\n",
        "print(f\"{text}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn6_Bj7I2_ah",
        "colab_type": "text"
      },
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJGgkBzI2TVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TdFkjIP7eCm",
        "colab_type": "text"
      },
      "source": [
        "Dataset import:\n",
        "\n",
        "*Portugese-English translation, with 50000 training examples, 1100 validation examples, and 2000 test examples*\n",
        "https://github.com/neulab/word-embeddings-for-nmt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpWt5Opu3C-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#returns dataset, dataset (version, features, num_examples etc.)\n",
        "#supervised means it's returned as a 2-tuple structure (input, label), rather than as a dictionary\n",
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
        "\n",
        "#seperate examples into training, tuning and testing groups (precategorised in dataset)\n",
        "train_examples, val_examples, test_examples = examples['train'], examples['validation'], examples['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko6J1sA9ATBv",
        "colab_type": "text"
      },
      "source": [
        "Subwords tokeniser (created with training set):\n",
        "\n",
        "*'Subword tokenization is a recent strategy from machine translation that helps us solve these problems by breaking unknown words into “subword units” - strings of characters like ing or eau - that still allow the downstream model to make intelligent decisions on words it doesn’t recognize.'*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDAIoX95AdBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokeniser_en = tfds.features.text.SubwordTextEncoder.build_from_corpus((en.numpy() for pt, en in train_exammples), target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QC1cEjUA1JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}